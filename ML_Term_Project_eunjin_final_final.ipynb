{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Definition\n",
    "\n",
    "* 주어진 데이터를 갖고 네트워크 칩입을 감지하는 Classfication Model을 설계하라.\n",
    "\n",
    "* 주어진 데이터를 가공하고, 수정하여도 무관하다.\n",
    "\n",
    "* 사용해 볼 수 있는 만큼 많은 모델을 시도하여 볼 것\n",
    "\n",
    "* 사용한 모델은 모두 Jupyter Notebook에 남길 것 (채점할 때 실행 가능하도록)\n",
    "\n",
    "* 보고서는 따로 워드로 제출할 것 (보고서 양식은 따로 없음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 데이터는 KDD Cup 1999 Dataset을 가공한 네트워크 칩입 감지 시스템용 데이터이다. 각 Feature들은 어떤 protocol type을 사용하는 지 혹은 어떤 service를 사용하는 지 등의 내용를 담고 있다. Class는 현재 네트워크가 침입을 당한 상태인 지 만약 침입을 당하였다면 어떤 종류의 침입을 당했는 지를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total 41 Features.\n",
    "\n",
    "duration: continuous.\n",
    "\n",
    "protocol_type: symbolic.\n",
    "\n",
    "service: Numeric, categorical\n",
    "\n",
    "flag: Numeric, categorical\n",
    "\n",
    "src_bytes: continuous.\n",
    "\n",
    "dst_bytes: continuous.\n",
    "\n",
    "land: symbolic.\n",
    "\n",
    "wrong_fragment: continuous.\n",
    "\n",
    "urgent: continuous.\n",
    "\n",
    "hot: continuous.\n",
    "\n",
    "num_failed_logins: continuous.\n",
    "\n",
    "logged_in: symbolic.\n",
    "\n",
    "num_compromised: continuous.\n",
    "\n",
    "root_shell: continuous.\n",
    "\n",
    "su_attempted: continuous.\n",
    "\n",
    "num_root: continuous.\n",
    "\n",
    "num_file_creations: continuous.\n",
    "\n",
    "num_shells: continuous.\n",
    "\n",
    "num_access_files: continuous.\n",
    "\n",
    "num_outbound_cmds: continuous.\n",
    "\n",
    "is_host_login: symbolic.\n",
    "\n",
    "is_guest_login: symbolic.\n",
    "\n",
    "count: continuous.\n",
    "\n",
    "srv_count: continuous.\n",
    "\n",
    "serror_rate: continuous.\n",
    "\n",
    "srv_serror_rate: continuous.\n",
    "\n",
    "rerror_rate: continuous.\n",
    "\n",
    "srv_rerror_rate: continuous.\n",
    "\n",
    "same_srv_rate: continuous.\n",
    "\n",
    "diff_srv_rate: continuous.\n",
    "\n",
    "srv_diff_host_rate: continuous.\n",
    "\n",
    "dst_host_count: continuous.\n",
    "\n",
    "dst_host_srv_count: continuous.\n",
    "\n",
    "dst_host_same_srv_rate: continuous.\n",
    "\n",
    "dst_host_diff_srv_rate: continuous.\n",
    "\n",
    "dst_host_same_src_port_rate: continuous.\n",
    "\n",
    "dst_host_srv_diff_host_rate: continuous.\n",
    "\n",
    "dst_host_serror_rate: continuous.\n",
    "\n",
    "dst_host_srv_serror_rate: continuous.\n",
    "\n",
    "dst_host_rerror_rate: continuous.\n",
    "\n",
    "dst_host_srv_rerror_rate: continuous.\n",
    "\n",
    "보다 자세한 설명은 http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html 를 참조(가공된 데이터이기 때문에, 사이트와 다른 점이 있음을 염두할것.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Normal\", \"dos\", \"u2r\", \"r2l\", \"probe\" 5개의 Class가 존재한다.\n",
    "\n",
    "Normal은 정상을 의미하며, 나머지 4개는 네트워크상 침입 기법들의 이름들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas로 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv 파일 불러와서 pandas 데이터프레임으로 저장하기\n",
    "data = pd.read_csv('desktop/train_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Identify categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'xAttack' has 5 categories\n",
      "Distribution of categories in protocol_type:\n",
      "icmp    102689\n",
      "udp      14993\n",
      "tcp       8291\n",
      "Name: protocol_type, dtype: int64\n",
      "Distribution of categories in service:\n",
      "25    40871\n",
      "50    21853\n",
      "12     9612\n",
      "20     8614\n",
      "55     7313\n",
      "Name: service, dtype: int64\n",
      "Distribution of categories in flag:\n",
      "2    74945\n",
      "4    34851\n",
      "1    11233\n",
      "5     2421\n",
      "3     1665\n",
      "Name: flag, dtype: int64\n",
      "Distribution of categories in xAttack:\n",
      "normal    67343\n",
      "dos       45927\n",
      "probe     11656\n",
      "r2l         995\n",
      "u2r          52\n",
      "Name: xAttack, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# colums that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n",
    "# explore categorical features\n",
    "# 숫자형태로된 categorical feature은 object형으로 인식하지 못한다 \n",
    "print('Training set:')\n",
    "for col_name in data.columns:\n",
    "    if data[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(data[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
    "print('Distribution of categories in protocol_type:')\n",
    "print(data['protocol_type'].value_counts().sort_values(ascending=False).head())\n",
    "\n",
    "print('Distribution of categories in service:')\n",
    "print(data['service'].value_counts().sort_values(ascending=False).head())\n",
    "\n",
    "print('Distribution of categories in flag:')\n",
    "print(data['flag'].value_counts().sort_values(ascending=False).head())\n",
    "\n",
    "print('Distribution of categories in xAttack:')\n",
    "print(data['xAttack'].value_counts().sort_values(ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>['icmp', 'udp', 'tcp']_0</th>\n",
       "      <th>['icmp', 'udp', 'tcp']_1</th>\n",
       "      <th>['icmp', 'udp', 'tcp']_2</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "      <td>5608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  service  flag  src_bytes  dst_bytes  land  wrong_fragment  \\\n",
       "0         0       18     1        482          0     0               0   \n",
       "1         0       39     1        143          0     0               0   \n",
       "2         0       44     3          0          0     0               0   \n",
       "3         0       22     1        229       5608     0               0   \n",
       "4         0       22     1        196        405     0               0   \n",
       "\n",
       "   urgent  hot  num_failed_logins   ...     dst_host_same_src_port_rate  \\\n",
       "0       0    0                  0   ...                              17   \n",
       "1       0    0                  0   ...                              88   \n",
       "2       0    0                  0   ...                               0   \n",
       "3       0    0                  0   ...                               3   \n",
       "4       0    0                  0   ...                               0   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                            0                     0   \n",
       "1                            0                     0   \n",
       "2                            0                   100   \n",
       "3                            4                     3   \n",
       "4                            0                     0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                         0                     5                         0   \n",
       "1                         0                     0                         0   \n",
       "2                        99                     0                         0   \n",
       "3                         1                     0                         1   \n",
       "4                         0                     0                         0   \n",
       "\n",
       "   ['icmp', 'udp', 'tcp']_0  ['icmp', 'udp', 'tcp']_1  \\\n",
       "0                         1                         0   \n",
       "1                         0                         0   \n",
       "2                         1                         0   \n",
       "3                         1                         0   \n",
       "4                         1                         0   \n",
       "\n",
       "   ['icmp', 'udp', 'tcp']_2  xAttack  \n",
       "0                         0        1  \n",
       "1                         1        1  \n",
       "2                         0        0  \n",
       "3                         0        1  \n",
       "4                         0        1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 침입 인지 아닌지만 True or false 로 \n",
    "new_columns = {\"xAttack\": {\"normal\": 1, \"dos\": 0, \"probe\": 0, \"r2l\": 0, \"u2r\": 0}}\n",
    "data.replace(new_columns, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "# label 인코딩 후 데이터 변경 - protocol_type\n",
    "le.fit_transform(data[\"protocol_type\"])\n",
    "data = data.apply(le.fit_transform)\n",
    "\n",
    "protocol_type_encoded = pd.get_dummies(data[\"protocol_type\"], prefix=['icmp', 'udp','tcp'])\n",
    "data = data.drop('protocol_type', axis=1)\n",
    "data = pd.concat([data,protocol_type_encoded],axis=1)\n",
    "\n",
    "\n",
    "# 클래스가 맨 마지막에 오도록  (예쁜 방법은 아니다...)\n",
    "xAttack_data = data['xAttack']\n",
    "data = data.drop('xAttack', axis=1)\n",
    "data = pd.concat([data,xAttack_data],axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Step 2: Feature Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataframes into X & Y\n",
    "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
    "# The “X ” set consists of predictor variables & The “Y” set consists of the outcome variable.\n",
    "\n",
    "Xdata = data.iloc[:,:-1]\n",
    "Ydata = data.iloc[:,-1]\n",
    "\n",
    "\n",
    "X = Xdata.values\n",
    "Y = Ydata.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Selection & ready for normalization & ready for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1) Remove Low Var Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Fits a number of randomized decision trees\n",
    "model = ExtraTreesClassifier(n_estimators = 30)\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Select the important features of previous model\n",
    "sel = SelectFromModel(model, prefit=True)\n",
    "\n",
    "# Subset features\n",
    "X_new = sel.transform(X)\n",
    "X_new.shape\n",
    "X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input variable MinMax Normalization based on Training data\n",
    "def standardization(Data,Data2):\n",
    "    return ((Data - np.mean(Data2, axis=0)) / np.std(Data2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "def plot_feature_importances(model):\n",
    "    n_features = np.shape(Train_Input_Normalized)[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), Use_Feature_Name)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "    plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 1 ) Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimportances = tree.feature_importances_\\nimport numpy as np\\nindices = np.argsort(importances)[::-1]\\nprint(\"Feature Ranking\")\\nfor i in range(10):\\n    print (i+1,indices[i],importances[indices[i]],data.columns[i])\\n'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "importances = tree.feature_importances_\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature Ranking\")\n",
    "for i in range(10):\n",
    "    print (i+1,indices[i],importances[indices[i]],data.columns[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.96435942213049686, 0.96261311319257026, 0.9628512462295602, 0.96594427244582048, 0.96324521711518618, 0.96578550448519485, 0.96253076129237125, 0.9617369214892435, 0.96197507343018174, 0.96388028895768829] \n",
      "\n",
      "Average accuracy:  0.963492182077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    tree.fit(Train_Input_Normalized, y_train)\n",
    "    acc = tree.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc) \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## entropy기준으로 한 트리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.96435942213049686, 0.96261311319257026, 0.9628512462295602, 0.96594427244582048, 0.96324521711518618, 0.96578550448519485, 0.96253076129237125, 0.9617369214892435, 0.96197507343018174, 0.96388028895768829] \n",
      "\n",
      "Average accuracy:  0.963492182077\n"
     ]
    }
   ],
   "source": [
    "newTree = DecisionTreeClassifier(criterion='entropy')\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    newTree.fit(Train_Input_Normalized, y_train)\n",
    "    acc = newTree.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc) \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.96491506588347353, 0.96293062390855688, 0.96301000158755357, 0.96578550448519485, 0.96300706517424783, 0.96665872826863541, 0.96308644915456065, 0.96276891323330949, 0.96165753750893068, 0.96388028895768829] \n",
      "\n",
      "Average accuracy:  0.963770017816\n"
     ]
    }
   ],
   "source": [
    "# max_depth를 설정해봄 \n",
    "newTree = DecisionTreeClassifier(criterion='entropy',max_depth=10)\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    newTree.fit(Train_Input_Normalized, y_train)\n",
    "    acc = newTree.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc) \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 2 ) RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.97372598825210355, 0.97197967931417684, 0.97237656770916014, 0.97491466222116374, 0.97094546320552511, 0.97356513455584659, 0.97269191077240613, 0.97094546320552511, 0.9714217670874018, 0.97308883067397001] \n",
      "\n",
      "Average accuracy:  0.9725655467\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier.\n",
    "#rf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=150,max_features=\"sqrt\",\n",
    "                           random_state=1026)\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "RFECV(RandomForestClassifier(), scoring='accuracy')\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "        \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    rf.fit(Train_Input_Normalized, y_train)\n",
    "    acc = rf.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select Most Important Features 했을때 성능이 좋아짐을 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.97372598825210355, 0.97197967931417684, 0.97237656770916014, 0.97491466222116374, 0.97094546320552511, 0.97356513455584659, 0.97269191077240613, 0.97094546320552511, 0.9714217670874018, 0.97308883067397001] \n",
      "\n",
      "Average accuracy:  0.9725655467\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier.\n",
    "#rf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=150,max_features=\"sqrt\",\n",
    "                           random_state=1026)\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "#Identify And Select Most Important Features\n",
    "sfm = SelectFromModel(rf, threshold=0.15)\n",
    "\n",
    "# threshold 값도 다양하게 바꿔봄 \n",
    "#(The threshold value to use for feature selection. Features whose importance is greater or equal are kept while the others are discarded.)\n",
    "# sfm = SelectFromModel(clf, threshold=0.1)\n",
    "\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X, Y)\n",
    "X = sfm.transform(X)\n",
    "\n",
    "RFECV(RandomForestClassifier(), scoring='accuracy')\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "        \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    rf.fit(Train_Input_Normalized, y_train)\n",
    "    acc = rf.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_feature_importances(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 3 ) GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.95967613906969362, 0.956262898872837, 0.95673916494681699, 0.96022862586330082, 0.95768833849329205, 0.96022862586330082, 0.95808525839485592, 0.9574501865523537, 0.95705326665078982, 0.95824402635548145] \n",
      "\n",
      "Average accuracy:  0.958165653106\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier.\n",
    "#gbrt = GradientBoostingClassifier(random_state=0,max_depth=1,learning_rate=0.01)\n",
    "gbrt = GradientBoostingClassifier(n_estimators=50,\n",
    "                           random_state=1026)\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "\n",
    "    gbrt.fit(Train_Input_Normalized, y_train)\n",
    "    acc = gbrt.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_feature_importances(gbrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 4 ) MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.91665343705350055, 0.91324019685664393, 0.91871725670741389, 0.93030086528538536, 0.91124871001031993, 0.92656981821068507, 0.92847503373819162, 0.91394776534095423, 0.9261728983091212, 0.91664682067158842] \n",
      "\n",
      "Average accuracy:  0.920197280218\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10,10))\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "\n",
    "    mlp.fit(Train_Input_Normalized, y_train)\n",
    "    acc = mlp.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "  \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden layer 변경해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.91657405937450387, 0.91355770757263055, 0.91887601206540725, 0.91871080415972062, 0.91132809399063264, 0.91886957212034615, 0.91513852504564575, 0.91394776534095423, 0.92220369929348256, 0.91688497261252677] \n",
      "\n",
      "Average accuracy:  0.916609121158\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5,2))\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "\n",
    "    mlp.fit(Train_Input_Normalized, y_train)\n",
    "    acc = mlp.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.91617717097952056, 0.91387521828861729, 0.91887601206540725, 0.91886957212034615, 0.91132809399063264, 0.91894895610065885, 0.91482098912439469, 0.91394776534095423, 0.91275700563626261, 0.91688497261252677] \n",
      "\n",
      "Average accuracy:  0.915648575626\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5))\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "\n",
    "    mlp.fit(Train_Input_Normalized, y_train)\n",
    "    acc = mlp.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc) \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 5 ) SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.91792347991744716, 0.91601841562152719, 0.92125734243530721, 0.9218861633722315, 0.91283638961657543, 0.9202190997856633, 0.91521790902595856, 0.91664682067158842, 0.91513852504564575, 0.91752004445502899] \n",
      "\n",
      "Average accuracy:  0.917466418995\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    svc.fit(Train_Input_Normalized, y_train)\n",
    "    acc = svc.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 6 ) LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.94046674075250036, 0.93760914430862041, 0.94014923003651374, 0.94030324680479482, 0.93760419147416052, 0.9401444788441693, 0.9385567992379138, 0.93903310311979038, 0.9391124871001032, 0.94062078272604588] \n",
      "\n",
      "Average accuracy:  0.93936002044\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    lr.fit(Train_Input_Normalized, y_train)\n",
    "    acc = lr.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Build the model & Step 5: Prediction & Evaluation (validation):\n",
    "\n",
    "# 7 ) KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.96221622479758695, 0.9588823622797269, 0.96031116050166698, 0.96618242438675872, 0.96078431372549022, 0.96134000158767963, 0.96126061760736681, 0.96157815352861797, 0.96149876954830515, 0.96427720885925217] \n",
      "\n",
      "Average accuracy:  0.961833123682\n"
     ]
    }
   ],
   "source": [
    "#k의 역할은 몇 번째로 가까운 데이터까지 살펴볼 것인가를 정한 숫자이다.\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "\n",
    "    neigh.fit(Train_Input_Normalized, y_train)\n",
    "    acc = neigh.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.96443879980949354, 0.96269249087156694, 0.9602317828226703, 0.96594427244582048, 0.96300706517424783, 0.96570612050488214, 0.96237199333174561, 0.96245137731205843, 0.9617369214892435, 0.96419782487893946] \n",
      "\n",
      "Average accuracy:  0.963277864864\n"
     ]
    }
   ],
   "source": [
    "# 다른 k값\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    \n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "\n",
    "    neigh.fit(Train_Input_Normalized, y_train)\n",
    "    acc = neigh.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 5: 자신의 best model   RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "standardization complete!\n",
      "Accuracy per fold:  [0.97372598825210355, 0.97197967931417684, 0.97237656770916014, 0.97491466222116374, 0.97094546320552511, 0.97356513455584659, 0.97269191077240613, 0.97094546320552511, 0.9714217670874018, 0.97308883067397001] \n",
      "\n",
      "Average accuracy:  0.9725655467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Create a random forest Classifier.\n",
    "rf = RandomForestClassifier(n_estimators=150,max_features=\"sqrt\",\n",
    "                           random_state=1026)\n",
    "\n",
    "#Identify And Select Most Important Features\n",
    "sfm = SelectFromModel(rf, threshold=0.15)\n",
    "# Train the selector\n",
    "sfm.fit(X, Y)\n",
    "X = sfm.transform(X)\n",
    "\n",
    "#Simple K-Fold cross validation. 10 folds. (split the data into 10 parts & fit on 9-parts & test accuracy on the remaining part)\n",
    "cv = KFold(len(data), n_folds=10)\n",
    "fold_accuracy = []\n",
    "\n",
    "for train, test in cv:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "\n",
    "    Train_Input_Normalized = copy.deepcopy(standardization(X_train,X_train))\n",
    "    Test_Input_Normalized = copy.deepcopy(standardization(X_test,X_train))\n",
    "    print(\"standardization complete!\")\n",
    "    \n",
    "    rf.fit(Train_Input_Normalized, y_train)\n",
    "    acc = rf.score(Test_Input_Normalized, y_test)\n",
    "    fold_accuracy.append(acc)  \n",
    "    \n",
    "print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
